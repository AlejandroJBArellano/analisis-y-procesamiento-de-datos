{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a42f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GU√çA PARA REPRODUCIR ESTE AN√ÅLISIS EN KAGGLE\n",
      "================================================================================\n",
      "\n",
      "# EN KAGGLE, REEMPLAZA LA RUTA CON:\n",
      "import pandas as pd\n",
      "df_train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
      "df_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n",
      "\n",
      "# TUS PASOS:\n",
      "# 1. Visualizar SalePrice (ya hecho arriba ‚úì)\n",
      "# 2. Detectar outliers en GrLivArea (ya hecho arriba ‚úì)\n",
      "# 3. Aplicar log1p a SalePrice (ya hecho arriba ‚úì)\n",
      "# 4. Transformar caracter√≠sticas sesgadas (ya hecho arriba ‚úì)\n",
      "# 5. PR√ìXIMO: Correlaci√≥n con SalePrice\n",
      "# 6. PR√ìXIMO: Feature engineering\n",
      "\n",
      "# PLANTILLA PARA VISUALIZAR CORRELACI√ìN:\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# Top 15 caracter√≠sticas correlacionadas con SalePrice\n",
      "corr = df_train.corr()['SalePrice'].sort_values(ascending=False)\n",
      "plt.figure(figsize=(10, 8))\n",
      "sns.barplot(x=corr.values, y=corr.index)\n",
      "plt.title('Top 15 Features Correlated with SalePrice')\n",
      "plt.show()\n",
      "\n",
      "# PLANTILLA PARA SCATTERPLOT:\n",
      "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
      "features_top = corr.index[1:10]  # Top 9 (excluyendo SalePrice)\n",
      "\n",
      "for idx, feat in enumerate(features_top):\n",
      "    row, col = idx // 3, idx % 3\n",
      "    axes[row, col].scatter(df_train[feat], df_train['SalePrice'], alpha=0.5)\n",
      "    axes[row, col].set_xlabel(feat)\n",
      "    axes[row, col].set_ylabel('SalePrice')\n",
      "    axes[row, col].set_title(f'{feat} vs SalePrice')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RECOMENDACI√ìN FINAL\n",
      "================================================================================\n",
      "\n",
      "üöÄ PR√ìXIMA SESI√ìN (Hito 3):\n",
      "   1. An√°lisis de correlaci√≥n entre features y SalePrice\n",
      "   2. Feature engineering: crear nuevas variables\n",
      "   3. Entrenar modelos: Linear Regression, Ridge, Lasso\n",
      "   4. Validaci√≥n cruzada y m√©tricas\n",
      "   5. Hacer predicciones en test set y enviar a Kaggle\n",
      "\n",
      "üìö DOCUMENTACI√ìN √öTIL:\n",
      "   - Pandas: https://pandas.pydata.org/docs/\n",
      "   - Scikit-learn: https://scikit-learn.org/\n",
      "   - Seaborn: https://seaborn.pydata.org/\n",
      "   - Kaggle Competitions: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/\n",
      "\n",
      "üí™ ¬°Est√°s listo para el siguiente nivel!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. GU√çA PR√ÅCTICA: REPRODUCIENDO EL AN√ÅLISIS EN KAGGLE\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GU√çA PARA REPRODUCIR ESTE AN√ÅLISIS EN KAGGLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "kaggle_template = \"\"\"\n",
    "# EN KAGGLE, REEMPLAZA LA RUTA CON:\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# TUS PASOS:\n",
    "# 1. Visualizar SalePrice (ya hecho arriba ‚úì)\n",
    "# 2. Detectar outliers en GrLivArea (ya hecho arriba ‚úì)\n",
    "# 3. Aplicar log1p a SalePrice (ya hecho arriba ‚úì)\n",
    "# 4. Transformar caracter√≠sticas sesgadas (ya hecho arriba ‚úì)\n",
    "# 5. PR√ìXIMO: Correlaci√≥n con SalePrice\n",
    "# 6. PR√ìXIMO: Feature engineering\n",
    "\n",
    "# PLANTILLA PARA VISUALIZAR CORRELACI√ìN:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Top 15 caracter√≠sticas correlacionadas con SalePrice\n",
    "corr = df_train.corr()['SalePrice'].sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=corr.values, y=corr.index)\n",
    "plt.title('Top 15 Features Correlated with SalePrice')\n",
    "plt.show()\n",
    "\n",
    "# PLANTILLA PARA SCATTERPLOT:\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "features_top = corr.index[1:10]  # Top 9 (excluyendo SalePrice)\n",
    "\n",
    "for idx, feat in enumerate(features_top):\n",
    "    row, col = idx // 3, idx % 3\n",
    "    axes[row, col].scatter(df_train[feat], df_train['SalePrice'], alpha=0.5)\n",
    "    axes[row, col].set_xlabel(feat)\n",
    "    axes[row, col].set_ylabel('SalePrice')\n",
    "    axes[row, col].set_title(f'{feat} vs SalePrice')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(kaggle_template)\n",
    "\n",
    "# Mostrar el template como nota\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMENDACI√ìN FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "üöÄ PR√ìXIMA SESI√ìN (Hito 3):\n",
    "   1. An√°lisis de correlaci√≥n entre features y SalePrice\n",
    "   2. Feature engineering: crear nuevas variables\n",
    "   3. Entrenar modelos: Linear Regression, Ridge, Lasso\n",
    "   4. Validaci√≥n cruzada y m√©tricas\n",
    "   5. Hacer predicciones en test set y enviar a Kaggle\n",
    "\n",
    "üìö DOCUMENTACI√ìN √öTIL:\n",
    "   - Pandas: https://pandas.pydata.org/docs/\n",
    "   - Scikit-learn: https://scikit-learn.org/\n",
    "   - Seaborn: https://seaborn.pydata.org/\n",
    "   - Kaggle Competitions: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/\n",
    "\n",
    "üí™ ¬°Est√°s listo para el siguiente nivel!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c4d9c3",
   "metadata": {},
   "source": [
    "## Resumen: Ciclo Completo del Hito 2\n",
    "\n",
    "### ‚úÖ Lo que hemos hecho:\n",
    "\n",
    "1. **Exploraci√≥n**: Vimos que SalePrice tiene una cola larga (muy sesgada)\n",
    "2. **Detecci√≥n de Outliers**: Comparamos IQR vs Isolation Forest\n",
    "3. **Missing Values**: Identificamos patrones de datos faltantes\n",
    "4. **Transformaciones**: Aplicamos log1p para normalizar distribuciones\n",
    "\n",
    "### üéØ Pr√≥ximos pasos (Hito 3):\n",
    "\n",
    "- **Selecci√≥n de caracter√≠sticas**: ¬øCu√°les variables son m√°s predictivas?\n",
    "- **Correlaci√≥n**: ¬øQu√© caracter√≠sticas est√°n relacionadas con SalePrice?\n",
    "- **Feature Engineering**: Crear nuevas variables derivadas\n",
    "- **Modelos**: Entrenar regressi√≥n lineal, ridge, lasso, etc.\n",
    "\n",
    "### üí° Lecciones aprendidas:\n",
    "\n",
    "- La distribuci√≥n de los datos importa: modelos lineales funcionan mejor con datos normales\n",
    "- No todos los outliers deben ser eliminate: algunos son datos reales (mansiones costosas)\n",
    "- Log1p es tu aliado: transforma distribuciones sesgadas en sim√©tricas\n",
    "- Always visualize: los gr√°ficos revelan patrones que los n√∫meros no muestran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8361adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 8. TRANSFORMAR OTRAS CARACTER√çSTICAS SESGADAS\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Seleccionar caracter√≠sticas num√©ricas sesgadas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m numerical_cols = \u001b[43mdf\u001b[49m.select_dtypes(include=[np.number]).columns.tolist()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Calcular skewness para cada columna\u001b[39;00m\n\u001b[32m      7\u001b[39m skewness_values = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 8. TRANSFORMAR OTRAS CARACTER√çSTICAS SESGADAS\n",
    "\n",
    "# Seleccionar caracter√≠sticas num√©ricas sesgadas\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Calcular skewness para cada columna\n",
    "skewness_values = {}\n",
    "for col in numerical_cols:\n",
    "    if df[col].notna().sum() > 0:  # Evitar columnas vac√≠as\n",
    "        skewness_values[col] = stats.skew(df[col])\n",
    "\n",
    "# Ordenar por skewness\n",
    "skewed_cols = sorted(skewness_values.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\nüìä CARACTER√çSTICAS M√ÅS SESGADAS:\")\n",
    "print(\"(Las primeras son candidatas para log1p o Box-Cox)\")\n",
    "for col, skew_val in skewed_cols[:15]:\n",
    "    print(f\"   {col:20s}: {skew_val:7.3f} {'(M√ÅS SESGADA)' if abs(skew_val) > 1 else ''}\")\n",
    "\n",
    "# Aplicar log1p a caracter√≠sticas sesgadas\n",
    "features_to_transform = [col for col, skew_val in skewed_cols if abs(skew_val) > 1 and col != 'SalePrice'][:5]\n",
    "\n",
    "print(f\"\\n‚ú® APLICANDO LOG1P A: {features_to_transform}\")\n",
    "\n",
    "for col in features_to_transform:\n",
    "    if (df[col] >= 0).all():  # Solo si son valores no-negativos\n",
    "        df_transformed[f'{col}_log1p'] = np.log1p(df[col])\n",
    "        original_skew = stats.skew(df[col])\n",
    "        transformed_skew = stats.skew(df_transformed[f'{col}_log1p'])\n",
    "        print(f\"   {col}: {original_skew:.3f} ‚Üí {transformed_skew:.3f} ({(1-abs(transformed_skew)/abs(original_skew))*100:.1f}% mejora)\")\n",
    "\n",
    "# Visualizar transformaciones\n",
    "if features_to_transform:\n",
    "    fig, axes = plt.subplots(len(features_to_transform), 2, figsize=(14, 4*len(features_to_transform)))\n",
    "    if len(features_to_transform) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, col in enumerate(features_to_transform):\n",
    "        # Original\n",
    "        axes[idx, 0].hist(df[col].dropna(), bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 0].set_title(f'{col} (Original)', fontweight='bold')\n",
    "        axes[idx, 0].set_ylabel('Frecuencia')\n",
    "        \n",
    "        # Transformed\n",
    "        axes[idx, 1].hist(df_transformed[f'{col}_log1p'], bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 1].set_title(f'{col} (After Log1p)', fontweight='bold')\n",
    "        axes[idx, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. APLICAR TRANSFORMACI√ìN LOG1P\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRANSFORMACI√ìN LOG1P\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear copia para transformaciones\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# Aplicar log1p a SalePrice\n",
    "df_transformed['SalePrice_log1p'] = np.log1p(df['SalePrice'])\n",
    "\n",
    "# Calcular estad√≠sticas\n",
    "print(\"\\nüìä SALEPRICE TRANSFORMADO:\")\n",
    "print(f\"   Original Skewness: {stats.skew(df['SalePrice']):.4f}\")\n",
    "print(f\"   Log1p Skewness: {stats.skew(df_transformed['SalePrice_log1p']):.4f}\")\n",
    "print(f\"   Reducci√≥n de sesgo: {(1 - abs(stats.skew(df_transformed['SalePrice_log1p'])) / abs(stats.skew(df['SalePrice']))) * 100:.2f}%\")\n",
    "\n",
    "# Visualizar transformaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].hist(df['SalePrice'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('SalePrice Original', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('SalePrice ($)')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Log1p\n",
    "axes[0, 1].hist(df_transformed['SalePrice_log1p'], bins=50, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('SalePrice After Log1p', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('log(SalePrice)')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "\n",
    "# KDE Original\n",
    "df['SalePrice'].plot(kind='kde', ax=axes[1, 0], color='blue', linewidth=2)\n",
    "axes[1, 0].set_title('KDE Original (Cola larga visible)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('SalePrice ($)')\n",
    "\n",
    "# KDE Log1p\n",
    "df_transformed['SalePrice_log1p'].plot(kind='kde', ax=axes[1, 1], color='red', linewidth=2)\n",
    "axes[1, 1].set_title('KDE After Log1p (Distribuci√≥n m√°s sim√©trica)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('log(SalePrice)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ú® OBSERVACI√ìN: ¬°La distribuci√≥n log1p es mucho m√°s sim√©trica y normal!\")\n",
    "print(f\"   Esto es exactamente lo que queremos para modelos predictivos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2009b",
   "metadata": {},
   "source": [
    "## Secci√≥n 4: Transformaciones - Normalizando Distribuciones Sesgadas\n",
    "\n",
    "**Objetivo**: Aplicar log1p a SalePrice y otras caracter√≠sticas sesgadas para convertirlas en distribuciones normales.\n",
    "\n",
    "Recordar: log1p(x) = ln(1 + x), esto permite manejar valores cero sin errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6976731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ANALIZAR MISSING VALUES\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE MISSING VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular porcentaje de NaN\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Ordenar por porcentage descendente\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"\\nüìä COLUMNAS CON VALORES NULOS:\")\n",
    "print(missing_data.to_string(index=False))\n",
    "\n",
    "# Visualizar\n",
    "if len(missing_data) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Tomar top 20\n",
    "    top_missing = missing_data.head(20)\n",
    "    \n",
    "    ax.barh(top_missing['Column'], top_missing['Missing_Percentage'], color='coral', edgecolor='black')\n",
    "    ax.set_xlabel('Porcentaje de Missing Values (%)', fontweight='bold')\n",
    "    ax.set_title('Top 20 Columnas con Missing Values', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # A√±adir etiquetas de porcentaje\n",
    "    for i, v in enumerate(top_missing['Missing_Percentage']):\n",
    "        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nüí° ESTRATEGIA:\")\n",
    "print(f\"   - Columnas con >90% nulos: Eliminar (no tenemos informaci√≥n)\")\n",
    "print(f\"   - PoolQC, Fence, MiscFeature: 'No' o 'None' (Feature Absence)\")\n",
    "print(f\"   - LotFrontage: Llenar con mediana (True Missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f859c4",
   "metadata": {},
   "source": [
    "## Secci√≥n 3: An√°lisis de Missing Values\n",
    "\n",
    "**Pregunta clave**: ¬øFaltan datos o simplemente esa caracter√≠stica no existe?\n",
    "\n",
    "En este dataset, \"NaN\" en PoolQC no significa \"dato faltante\" sino \"la casa no tiene piscina\". Debemos distinguir entre:\n",
    "- **Feature Absence**: No tiene esa caracter√≠stica (llenar con 'None')\n",
    "- **True Missing**: Error de entrada (llenar con mediana o eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74494a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DETECTAR OUTLIERS CON ISOLATION FOREST (Multivariado)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"M√âTODO 2: ISOLATION FOREST (MULTIVARIADO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Preparar datos: normalizar\n",
    "X = df[key_features].copy()\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Aplicar Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "outlier_predictions = iso_forest.fit_predict(X_scaled)\n",
    "outliers_if = np.where(outlier_predictions == -1)[0]\n",
    "\n",
    "print(f\"\\nüéØ TOTAL OUTLIERS ISOLATION FOREST: {len(outliers_if)}\")\n",
    "print(f\"   Indices: {sorted(outliers_if[:10])}...\")  # Mostrar primeros 10\n",
    "\n",
    "# Visualizar\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# GrLivArea vs SalePrice\n",
    "normal_idx = set(range(len(df))) - set(outliers_if)\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(df.iloc[list(normal_idx)]['GrLivArea'], df.iloc[list(normal_idx)]['SalePrice'], \n",
    "          alpha=0.5, color='blue', label='Normal')\n",
    "ax.scatter(df.iloc[outliers_if]['GrLivArea'], df.iloc[outliers_if]['SalePrice'], \n",
    "          alpha=0.8, color='red', s=100, marker='o', label='Outlier IF')\n",
    "ax.set_xlabel('GrLivArea (sq ft)')\n",
    "ax.set_ylabel('SalePrice ($)')\n",
    "ax.set_title('Scatter: GrLivArea vs SalePrice', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# GrLivArea\n",
    "ax = axes[0, 1]\n",
    "ax.hist(df.iloc[list(normal_idx)]['GrLivArea'], bins=30, alpha=0.6, color='blue', label='Normal')\n",
    "ax.hist(df.iloc[outliers_if]['GrLivArea'], bins=10, alpha=0.8, color='red', label='Outlier IF')\n",
    "ax.set_title('Distribuci√≥n: GrLivArea', fontweight='bold')\n",
    "ax.set_xlabel('GrLivArea (sq ft)')\n",
    "ax.legend()\n",
    "\n",
    "# LotArea\n",
    "ax = axes[1, 0]\n",
    "ax.hist(df.iloc[list(normal_idx)]['LotArea'], bins=30, alpha=0.6, color='blue', label='Normal')\n",
    "ax.hist(df.iloc[outliers_if]['LotArea'], bins=10, alpha=0.8, color='red', label='Outlier IF')\n",
    "ax.set_title('Distribuci√≥n: LotArea', fontweight='bold')\n",
    "ax.set_xlabel('LotArea (sq ft)')\n",
    "ax.legend()\n",
    "\n",
    "# SalePrice\n",
    "ax = axes[1, 1]\n",
    "ax.hist(df.iloc[list(normal_idx)]['SalePrice'], bins=30, alpha=0.6, color='blue', label='Normal')\n",
    "ax.hist(df.iloc[outliers_if]['SalePrice'], bins=10, alpha=0.8, color='red', label='Outlier IF')\n",
    "ax.set_title('Distribuci√≥n: SalePrice', fontweight='bold')\n",
    "ax.set_xlabel('SalePrice ($)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparar ambos m√©todos\n",
    "print(f\"\\nüìä COMPARACI√ìN DE M√âTODOS:\")\n",
    "print(f\"   Outliers IQR: {len(outliers_iqr_all)}\")\n",
    "print(f\"   Outliers IF: {len(outliers_if)}\")\n",
    "print(f\"   Ambos m√©todos coinciden: {len(outliers_iqr_all & set(outliers_if))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DETECTAR OUTLIERS CON IQR (Univariado)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"M√âTODO 1: IQR (UNIVARIADO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Seleccionar caracter√≠sticas clave\n",
    "key_features = ['GrLivArea', 'LotArea', 'TotalBsmtSF']\n",
    "\n",
    "# Funci√≥n para detectar outliers por IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)].index\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Aplicar IQR a cada caracter√≠stica\n",
    "outliers_iqr_all = set()\n",
    "for feature in key_features:\n",
    "    outliers, lb, ub = detect_outliers_iqr(df, feature)\n",
    "    outliers_iqr_all.update(outliers)\n",
    "    print(f\"\\nüìå {feature}:\")\n",
    "    print(f\"   Outliers detectados: {len(outliers)}\")\n",
    "    print(f\"   L√≠mites: [{lb:.2f}, {ub:.2f}]\")\n",
    "\n",
    "print(f\"\\nüéØ TOTAL OUTLIERS IQR: {len(outliers_iqr_all)}\")\n",
    "\n",
    "# Visualizar outliers con IQR\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    outliers, lb, ub = detect_outliers_iqr(df, feature)\n",
    "    \n",
    "    # Scatter plot\n",
    "    normal = df[~df.index.isin(outliers)]\n",
    "    outlier_pts = df[df.index.isin(outliers)]\n",
    "    \n",
    "    axes[idx].scatter(normal.index, normal[feature], alpha=0.5, color='blue', label='Normal')\n",
    "    axes[idx].scatter(outlier_pts.index, outlier_pts[feature], alpha=0.8, color='red', s=100, marker='o', label='Outlier IQR')\n",
    "    axes[idx].axhline(lb, color='orange', linestyle='--', linewidth=1, label=f'L√≠mites IQR')\n",
    "    axes[idx].axhline(ub, color='orange', linestyle='--', linewidth=1)\n",
    "    \n",
    "    axes[idx].set_title(f'Outliers IQR: {feature}', fontweight='bold')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9239f24a",
   "metadata": {},
   "source": [
    "## Secci√≥n 2: Detecci√≥n de Outliers - IQR vs Isolation Forest\n",
    "\n",
    "**Caso de uso real**: El creator del dataset advierte que hay casas con mucha √°rea habitable (GrLivArea) que se vendieron muy baratas. Esos son datos an√≥malos que debemos identificar.\n",
    "\n",
    "Usaremos dos m√©todos:\n",
    "- **IQR**: M√©todo univariado (ve cada columna independientemente)\n",
    "- **Isolation Forest**: M√©todo multivariado (ve combinaciones de caracter√≠sticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ANALIZAR DISTRIBUCI√ìN DEL SALEPRICE (TARGET)\n",
    "\n",
    "# Calcular estad√≠sticas descriptivas\n",
    "saleprice_stats = df['SalePrice'].describe()\n",
    "skewness = stats.skew(df['SalePrice'])\n",
    "kurtosis = stats.kurtosis(df['SalePrice'])\n",
    "\n",
    "print(\"üìä ESTAD√çSTICAS DE SALEPRICE:\")\n",
    "print(saleprice_stats)\n",
    "print(f\"\\nüìà Medidas de Forma:\")\n",
    "print(f\"   Skewness (Sesgo): {skewness:.4f}\")\n",
    "print(f\"   Kurtosis (Curtosis): {kurtosis:.4f}\")\n",
    "\n",
    "# Crear visualizaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(df['SalePrice'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribuci√≥n Original de SalePrice', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('SalePrice ($)')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].axvline(df['SalePrice'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: ${df[\"SalePrice\"].mean():,.0f}')\n",
    "axes[0, 0].axvline(df['SalePrice'].median(), color='green', linestyle='--', linewidth=2, label=f'Mediana: ${df[\"SalePrice\"].median():,.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# KDE Plot\n",
    "df['SalePrice'].plot(kind='kde', ax=axes[0, 1], color='blue', linewidth=2)\n",
    "axes[0, 1].set_title('Density Plot de SalePrice', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('SalePrice ($)')\n",
    "axes[0, 1].fill_between(df['SalePrice'].plot(kind='kde', ax=axes[0, 1]).get_lines()[0].get_xdata(), \n",
    "                         df['SalePrice'].plot(kind='kde').get_lines()[0].get_ydata(), alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "axes[1, 0].boxplot(df['SalePrice'], vert=True)\n",
    "axes[1, 0].set_title('Boxplot de SalePrice (Outliers visibles)', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('SalePrice ($)')\n",
    "\n",
    "# Q-Q Plot\n",
    "stats.probplot(df['SalePrice'], dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (Comparaci√≥n con Normal)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° OBSERVACI√ìN: ¬øVes la cola hacia la derecha? Eso son mansiones caras que distorsionan la distribuci√≥n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdb7f8",
   "metadata": {},
   "source": [
    "## Secci√≥n 1: An√°lisis Exploratorio del Target (SalePrice)\n",
    "\n",
    "**Pregunta clave**: ¬øTiene la distribuci√≥n de precios una \"cola larga\" a la derecha?\n",
    "\n",
    "Esto es importante porque los modelos estad√≠sticos funcionan mejor con distribuciones normales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CARGAR DATASET\n",
    "\n",
    "# Cargar desde archivo CSV local\n",
    "df = pd.read_csv('/Users/alepulsito/projects/hybridge/analisis-y-procesamiento-de-datos/hito-2/AmesHousing.csv')\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado correctamente\")\n",
    "print(f\"\\nüìä Informaci√≥n General:\")\n",
    "print(f\"   Dimensiones: {df.shape[0]} registros √ó {df.shape[1]} caracter√≠sticas\")\n",
    "print(f\"   Columnass: {df.columns.tolist()[:10]}...\")\n",
    "print(f\"\\nüìà Primeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4bee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTAR LIBRER√çAS NECESARIAS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaciones\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea9697",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques\n",
    "## An√°lisis Exploratorio y Preparaci√≥n de Datos (Hito 2)\n",
    "\n",
    "Este notebook implementa un pipeline profesional de preparaci√≥n de datos para el dataset **\"House Prices: Advanced Regression Techniques\"** de Kaggle.\n",
    "\n",
    "### üéØ Objetivos del Hito 2:\n",
    "1. **Detecci√≥n de Outliers**: IQR vs Isolation Forest\n",
    "2. **An√°lisis de Missing Values**: Identificar patrones y estrategias de imputaci√≥n\n",
    "3. **Transformaciones**: Log1p y Box-Cox para normalizar distribuciones sesgadas\n",
    "4. **Visualizaci√≥n**: Comparar antes y despu√©s de cada transformaci√≥n\n",
    "\n",
    "### üìä Dataset:\n",
    "- **1,460 casas** en Ames, Iowa\n",
    "- **79 caracter√≠sticas** incluyendo √°rea habitable, n√∫mero de habitaciones, calidad, etc.\n",
    "- **Target**: SalePrice (Precio de venta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
